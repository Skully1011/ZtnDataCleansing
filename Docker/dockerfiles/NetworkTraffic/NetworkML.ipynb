{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGCydVBOqmIB"
      },
      "source": [
        "##Your machine learning stuff needed and parsing packages idk if you'll use a Jupyter but here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZmrQu66qZyk"
      },
      "outputs": [],
      "source": [
        "!pip install scapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9fKmm_6qjtU"
      },
      "outputs": [],
      "source": [
        "#needed packages\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from scapy.all import *\n",
        "from scapy.all import rdpcap\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdeGQzgBqtYr"
      },
      "outputs": [],
      "source": [
        "Pcap_file_path = #'Path to your pcap'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z08HYUnqyH9"
      },
      "outputs": [],
      "source": [
        "from scapy.all import rdpcap\n",
        "import pandas as pd\n",
        "#parsing function and then you can use it do put the packets into a dataframe\n",
        "def parse_pcap_to_df(pcap_file):\n",
        "    packets = rdpcap(pcap_file)\n",
        "\n",
        "    packet_data = []\n",
        "\n",
        "    for packet in packets:\n",
        "        if packet.haslayer('IP'):\n",
        "            src_ip = packet['IP'].src\n",
        "            dst_ip = packet['IP'].dst\n",
        "\n",
        "            src_port = packet['TCP'].sport if packet.haslayer('TCP') else 0\n",
        "            dst_port = packet['TCP'].dport if packet.haslayer('TCP') else 0\n",
        "\n",
        "            packet_size = len(packet)\n",
        "            packet_flags = packet.sprintf(\"%TCP.flags%\")\n",
        "            packet_time = packet.time\n",
        "            packet_header = packet.summary()\n",
        "            packet_protocol = packet['IP'].proto\n",
        "\n",
        "            packet_info = [src_ip, dst_ip, src_port, dst_port, packet_size, packet_flags, packet_time, packet_header, packet_protocol]\n",
        "            packet_data.append(packet_info)\n",
        "\n",
        "    df_columns = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'packet_size', 'packet_flags', 'packet_time', 'packet_header', 'packet_protocol']\n",
        "    packet_df = pd.DataFrame(packet_data, columns=df_columns)\n",
        "\n",
        "    return packet_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRrDhoN1q4YR"
      },
      "outputs": [],
      "source": [
        "#make mroe of these functions to fill your parameters\n",
        "def IP_valid:\n",
        "  for row in (pcap):\n",
        "    if src_IP[3:] != \"\" or \"\" #etc add all illegal\n",
        "\n",
        "    pd.drop(row)\n",
        "\n",
        "  return packet_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY_mfMYZriln"
      },
      "outputs": [],
      "source": [
        "#probs want a function that will label them into the three classes you presented them on\n",
        "#make it a function with parameters\n",
        "df.add_column('Malicious')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyvmVlzRsGl1"
      },
      "source": [
        "#Beginning of splitting data up for your Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkI-8CevsM5E"
      },
      "source": [
        "##Only include columns you need dont want to overload the function and overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqRLiahsXaA"
      },
      "source": [
        "if you need to scale or transform your data let me know"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFOOIQNzrtqI"
      },
      "outputs": [],
      "source": [
        "#Train test split shit\n",
        "from sklearn.model_selection import train_test_split\n",
        "#drop all columns of the labeling for train keep all deleted test and then you get\n",
        "#the train and test y values(things that go into predicting as well against (aka same stuff just without some things\n",
        "#i really dont remember the technicalities))\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=['Exited']).values, df.Exited.values,\n",
        "                                                    test_size=0.2, random_state=42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x__-knZcsF_s"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the Decision Tree classifier on the training data\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aftWRlPLs0Nk"
      },
      "source": [
        "Also including a random forest and K Neighbors Classifier just in case these would yield more accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca3NP5kasynG"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the Random Forest classifier on the training data\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01P04-a6s60N"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the Random Forest classifier on the training data\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpXZLUOBs67g"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the KNN classifier on the training data\n",
        "k = 3 #geographical\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
