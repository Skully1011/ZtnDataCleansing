{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGCydVBOqmIB"
      },
      "source": [
        "##Your machine learning stuff needed and parsing packages idk if you'll use a Jupyter but here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFahd0fDucWV"
      },
      "source": [
        "You can put this in a .py file and it wil make http normal traffic and video streaming traffic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZmrQu66qZyk",
        "outputId": "9e310c84-5062-4e3e-950b-24b3793943d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.5.0.tar.gz (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scapy\n",
            "  Building wheel for scapy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scapy: filename=scapy-2.5.0-py2.py3-none-any.whl size=1444330 sha256=c6ba1a5ea5c84defa3ca9b35a199b1a861ee8f5a10ba74d9a44888b3ce698ce2\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/b7/03/8344d8cf6695624746311bc0d389e9d05535ca83c35f90241d\n",
            "Successfully built scapy\n",
            "Installing collected packages: scapy\n",
            "Successfully installed scapy-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q_ZS9i0yFXm",
        "outputId": "7cfa648f-e111-4a28-b449-37cbadfe6cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75.181.196.138\n"
          ]
        }
      ],
      "source": [
        "#random IP if needed function\n",
        "import random\n",
        "def RANDIP():\n",
        "    return \".\".join(str(random.randint(0, 255)) for _ in range(4))\n",
        "\n",
        "# Using the RANDIP() function\n",
        "random_ip = RANDIP()\n",
        "print(random_ip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPmkweD3vC8r"
      },
      "outputs": [],
      "source": [
        "from scapy.all import *\n",
        "import random\n",
        "\n",
        "#replace these if needed\n",
        "dest_ip = \"192.168.1.10\"\n",
        "src_ip = \"192.168.1.20\" #(or you can do RANDIP())\n",
        "\n",
        "getStr = f'GET / HTTP/1.1\\r\\nHost: {dest_ip}\\r\\nAccept-Encoding: gzip, deflate\\r\\n\\r\\n'\n",
        "number_of_http_requests = 7\n",
        "\n",
        "counter = 0\n",
        "\n",
        "while counter < number_of_http_requests:\n",
        "    #sending syn packet to establish tcp\n",
        "    syn = IP(dst=dest_ip, src=src_ip) / TCP(sport=random.randint(1025, 65500), dport=80, flags='S')\n",
        "    #receive the syn ack from server\n",
        "    syn_ack = sr1(syn)\n",
        "\n",
        "    if syn_ack:\n",
        "        # Send ACK\n",
        "        ack = IP(dst=dest_ip, src=src_ip) / TCP(dport=80, sport=syn_ack[TCP].dport,\n",
        "                                                seq=syn_ack[TCP].ack, ack=syn_ack[TCP].seq + 1, flags='A')\n",
        "        send(ack)\n",
        "\n",
        "        #sending http get\n",
        "        http_get = IP(dst=dest_ip, src=src_ip) / TCP(dport=80, sport=syn_ack[TCP].dport,\n",
        "                                                     seq=syn_ack[TCP].ack, ack=syn_ack[TCP].seq + 1, flags='PA') / getStr\n",
        "        send(http_get)\n",
        "\n",
        "    counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9fKmm_6qjtU"
      },
      "outputs": [],
      "source": [
        "#needed packages\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from scapy.all import *\n",
        "from scapy.all import rdpcap\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdeGQzgBqtYr"
      },
      "outputs": [],
      "source": [
        "Pcap_file_path = #'Path to your pcap'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z08HYUnqyH9"
      },
      "outputs": [],
      "source": [
        "from scapy.all import rdpcap\n",
        "import pandas as pd\n",
        "#parsing function and then you can use it do put the packets into a dataframe\n",
        "def parse_pcap_to_df(pcap_file):\n",
        "    packets = rdpcap(pcap_file)\n",
        "\n",
        "    packet_data = []\n",
        "\n",
        "    for packet in packets:\n",
        "        if packet.haslayer('IP'):\n",
        "            src_ip = packet['IP'].src\n",
        "            dst_ip = packet['IP'].dst\n",
        "\n",
        "            src_port = packet['TCP'].sport if packet.haslayer('TCP') else 0\n",
        "            dst_port = packet['TCP'].dport if packet.haslayer('TCP') else 0\n",
        "\n",
        "            packet_size = len(packet)\n",
        "            packet_flags = packet.sprintf(\"%TCP.flags%\")\n",
        "            packet_time = packet.time\n",
        "            packet_header = packet.summary()\n",
        "            packet_protocol = packet['IP'].proto\n",
        "\n",
        "            packet_info = [src_ip, dst_ip, src_port, dst_port, packet_size, packet_flags, packet_time, packet_header, packet_protocol]\n",
        "            packet_data.append(packet_info)\n",
        "\n",
        "    df_columns = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'packet_size', 'packet_flags', 'packet_time', 'packet_header', 'packet_protocol']\n",
        "    packet_df = pd.DataFrame(packet_data, columns=df_columns)\n",
        "\n",
        "    return packet_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRrDhoN1q4YR"
      },
      "outputs": [],
      "source": [
        "#make mroe of these functions to fill your parameters\n",
        "def IP_valid:\n",
        "  for row in (pcap):\n",
        "    if src_IP[3:] != \"\" or \"\" #etc add all illegal\n",
        "\n",
        "    pd.drop(row)\n",
        "\n",
        "  return packet_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY_mfMYZriln"
      },
      "outputs": [],
      "source": [
        "#probs want a function that will label them into the three classes you presented them on\n",
        "#make it a function with parameters\n",
        "df.add_column('Malicious')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyvmVlzRsGl1"
      },
      "source": [
        "# Beginning of splitting data up for your Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkI-8CevsM5E"
      },
      "source": [
        "## Only include columns you need dont want to overload the function and overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqRLiahsXaA"
      },
      "source": [
        "if you need to scale or transform your data let me know"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFOOIQNzrtqI"
      },
      "outputs": [],
      "source": [
        "#Train test split shit\n",
        "from sklearn.model_selection import train_test_split\n",
        "#drop all columns of the labeling for train keep all deleted test and then you get\n",
        "#the train and test y values(things that go into predicting as well against (aka same stuff just without some things\n",
        "#i really dont remember the technicalities))\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=['Exited']).values, df.Exited.values,\n",
        "                                                    test_size=0.2, random_state=42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x__-knZcsF_s"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the Decision Tree classifier on the training data\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aftWRlPLs0Nk"
      },
      "source": [
        "Also including a random forest and K Neighbors Classifier just in case these would yield more accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca3NP5kasynG"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the Random Forest classifier on the training data\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01P04-a6s60N"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the Random Forest classifier on the training data\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpXZLUOBs67g"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the KNN classifier on the training data\n",
        "k = 3 #geographical\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "#Predictions on the testing data\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "#Classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "#Print the classification report\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369219cbeaf94c5a1a585149417d4385040fa94a2dba42dc7e12a8b1008bb5a1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
